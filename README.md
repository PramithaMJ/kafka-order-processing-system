# Kafka Order Processing System

**Production-Ready Microservices with Apache Kafka & Avro Serialization**

[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.3.5-brightgreen.svg)](https://spring.io/projects/spring-boot)
[![Kafka](https://img.shields.io/badge/Apache%20Kafka-3.7.1-black.svg)](https://kafka.apache.org/)
[![Confluent](https://img.shields.io/badge/Confluent%20Platform-7.6.0-blue.svg)](https://www.confluent.io/)
[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED.svg)](https://www.docker.com/)
[![Java](https://img.shields.io/badge/Java-17%20LTS-orange.svg)](https://openjdk.org/)
[![Avro](https://img.shields.io/badge/Apache%20Avro-1.11.3-red.svg)](https://avro.apache.org/)

## EG/2020/3990 - Jayasooriya LPM

## Table of Contents

- [Overview](#overview)
- [Dashboard Demo](#-dashboard-demo)
- [Quick Start](#quick-start)
- [System Architecture](#system-architecture)
- [Features](#features)
- [Technology Stack](#technology-stack)
- [Project Structure](#project-structure)
- [Deployment Options](#deployment-options)
- [API Documentation](#api-documentation)
- [Monitoring & Operations](#monitoring--operations)

## Overview

A **production-grade distributed order processing system** built with Apache Kafka, demonstrating enterprise-level event streaming patterns, fault tolerance, and microservices architecture.

### Key Capabilities

**High Availability** - 3-node Kafka cluster with RF=3, min ISR=2
**Schema Management** - Confluent Schema Registry with Avro serialization
**Fault Tolerance** - Automatic retry with exponential backoff + Dead Letter Queue
**Real-time Aggregation** - Thread-safe running average calculation
**Web Dashboard** - Modern UI for monitoring and order creation (Port 3000)
**Containerized** - Full Docker Compose orchestration with health checks
**Observable** - Kafka UI dashboard, structured logging, metrics endpoints
**Production-Ready** - Idempotent producers, manual commits, graceful shutdown

## Dashboard Demo

### Access the Interactive Dashboard

```
http://localhost:3000
```

**Features**:

- **Real-time statistics** - Total orders, running average, revenue, success rate
- **Order creation** - Interactive form with random data generation
- **Cluster monitoring** - Health status for all 9 containers
- **Service health** - Producer and consumer status with health checks
- **Order history** - Recent orders table with status tracking
- **Quick actions** - Batch orders, export data, manual refresh

**Quick Start**:

```bash
./infrastructure/scripts/start-dashboard.sh
# Opens browser automatically at http://localhost:3000
```

## Quick Start

### Prerequisites

- **Docker Desktop** (version 20.x or higher)
- **Docker Compose** (version 2.x or higher)
- **8GB RAM** minimum for Docker
- **macOS/Linux** (Windows with WSL2)

### One-Command Deployment

```bash
# Clone repository
git clone <repository-url>
cd Big-data-Assignment

# Start entire system (infrastructure + services)
./infrastructure/scripts/quick-start.sh
```

**That's it!** The script will:

1. Start ZooKeeper
2. Start 3 Kafka brokers
3. Start Schema Registry
4. Build & deploy Producer service
5. Build & deploy Consumer service
6. Start Kafka UI
7. Create topics (orders, orders-retry, orders-dlq)
8. Run health checks

**System Ready in ~60 seconds!**

### Verify Deployment

```bash
# Check all containers are healthy
docker ps

# Test Producer service
curl http://localhost:8090/actuator/health

# Test Consumer service
curl http://localhost:8082/actuator/health

# Access Kafka UI
open http://localhost:8080
```

### Send Your First Order

```bash
curl -X POST "http://localhost:8090/api/orders?orderId=DEMO001&product=Laptop&price=999.99"
```

**Check the result:**

```bash
curl http://localhost:8082/api/consumer/stats | python3 -m json.tool
```

## System Architecture

### High-Level Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Dashboard       â”‚         â”‚       Kafka Cluster (3 nodes)    â”‚         â”‚  Consumer Service   â”‚
â”‚    (Port 3000)      â”‚         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚         â”‚    (Port 8082)      â”‚
â”‚                     â”‚    â”Œâ”€â”€â”€â–¶â”‚  â”‚ kafka1 â”‚ kafka2 â”‚  kafka3  â”‚  â”‚â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚                     â”‚
â”‚  Web Interface:     â”‚    â”‚    â”‚  â”‚ :9092  â”‚ :9093  â”‚  :9094   â”‚  â”‚         â”‚  Processes:         â”‚
â”‚  â€¢ Order creation   â”‚    â”‚    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚         â”‚  â€¢ Order validation â”‚
â”‚  â€¢ Statistics view  â”‚    â”‚    â”‚           RF=3, min ISR=2        â”‚         â”‚  â€¢ Running average  â”‚
â”‚  â€¢ System monitor   â”‚    â”‚    â”‚                                  â”‚         â”‚  â€¢ Retry handling   â”‚
â”‚  â€¢ Real-time updatesâ”‚    â”‚    â”‚  Topics:                         â”‚         â”‚  â€¢ DLQ processing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚    â”‚  â€¢ orders (3 partitions)         â”‚         â”‚  â€¢ Stats API        â”‚
           â”‚               â”‚    â”‚  â€¢ orders-retry (3 partitions)   â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚               â”‚    â”‚  â€¢ orders-dlq (1 partition)      â”‚                    â”‚
           v               â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚                  â”‚                                         â”‚
â”‚  Producer Service   â”‚â”€â”€â”€â”€â”˜                  â”‚                                         â”‚
â”‚    (Port 8090)      â”‚                       â”‚                                         â”‚
â”‚                     â”‚                       v                                         â”‚
â”‚  REST API:          â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â€¢ POST /api/orders â”‚         â”‚         ZooKeeper                â”‚              v     â”‚
â”‚  â€¢ Avro Serializer  â”‚         â”‚        (Port 2181)               â”‚                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                                  â”‚                   â”‚
           â”‚                    â”‚  â€¢ Cluster coordination          â”‚                   â”‚
           v                    â”‚  â€¢ Leader election               â”‚                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚  â€¢ Broker metadata               â”‚                   â”‚
â”‚  Schema Registry    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚    (Port 8081)      â”‚                       â”‚                                         â”‚
â”‚                     â”‚                       v                                         v
â”‚  â€¢ Schema storage   â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â€¢ Schema evolution â”‚         â”‚          Kafka UI                â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”‚  Dashboard Stats    â”‚
â”‚  â€¢ Validation       â”‚         â”‚        (Port 8080)               â”‚         â”‚   GET /stats        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚                                  â”‚         â”‚   (Port 8082)       â”‚
                                â”‚  â€¢ Visual monitoring             â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚  â€¢ Message browser               â”‚
                                â”‚  â€¢ Consumer groups               â”‚
                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                                     9 Containers Total
```

### Message Flow

**1. Normal Flow (Happy Path)**

```
Client â†’ Producer API â†’ Avro Serialization â†’ Kafka Topic â†’ Consumer â†’ Process â†’ Running Average 
```

**2. Retry Flow (Temporary Failure)**

```
Consumer â†’ Processing Error â†’ orders-retry topic â†’ Exponential Backoff (2s, 4s, 8s) â†’ Retry â†’ Success 
```

**3. DLQ Flow (Permanent Failure)**

```
Consumer â†’ 3 Failed Retries â†’ orders-dlq topic â†’ Manual Investigation â†’ Fix & Reprocess ðŸ”§
```

### Container Architecture


| Container            | Image                                 | Port | Purpose                  |
| -------------------- | ------------------------------------- | ---- | ------------------------ |
| **zookeeper**        | confluentinc/cp-zookeeper:7.6.0       | 2181 | Cluster coordination     |
| **kafka1**           | confluentinc/cp-kafka:7.6.0           | 9092 | Kafka broker #1          |
| **kafka2**           | confluentinc/cp-kafka:7.6.0           | 9093 | Kafka broker #2          |
| **kafka3**           | confluentinc/cp-kafka:7.6.0           | 9094 | Kafka broker #3          |
| **schema-registry**  | confluentinc/cp-schema-registry:7.6.0 | 8081 | Avro schema management   |
| **kafka-ui**         | provectuslabs/kafka-ui:latest         | 8080 | Visual monitoring        |
| **producer-service** | Custom (Spring Boot 3.3.5)            | 8090 | Order creation API       |
| **consumer-service** | Custom (Spring Boot 3.3.5)            | 8082 | Order processing + stats |

---

## Features

### 1. High Availability

- **3-node Kafka cluster** with replication factor 3
- **Automatic failover** - survives single broker failure
- **No single point of failure** - all data replicated

### 2. Schema Management

- **Avro binary serialization** - 50% smaller than JSON
- **Schema Registry** - centralized schema versioning
- **Schema evolution** - backward/forward compatibility

### 3. Fault Tolerance

- **Retry mechanism** - automatic retry with exponential backoff
- **Dead Letter Queue** - preserve failed messages for investigation
- **Manual commits** - at-least-once delivery guarantee
- **Idempotent producer** - exactly-once semantics

### 4. Real-time Processing

- **Running average calculation** - thread-safe aggregation
- **Parallel processing** - 3 partitions for throughput
- **Low latency** - sub-second processing times

### 5. Observability

- **Kafka UI** - visual dashboard for monitoring
- **Health checks** - actuator endpoints for all services
- **Structured logging** - detailed processing logs
- **Consumer metrics** - lag, throughput, success rate

### 6. Production-Ready

- **Containerized** - Docker Compose orchestration
- **Health checks** - all containers monitored
- **Graceful shutdown** - proper cleanup on stop
- **Resource optimized** - multi-stage Dockerfiles

---

## Technology Stack

### Core Technologies


| Category           | Technology         | Version | Why?                                  |
| ------------------ | ------------------ | ------- | ------------------------------------- |
| **Message Broker** | Apache Kafka       | 3.7.1   | Industry standard for event streaming |
| **Platform**       | Confluent Platform | 7.6.0   | Enterprise Kafka distribution         |
| **Serialization**  | Apache Avro        | 1.11.3  | Binary format, schema evolution       |
| **Framework**      | Spring Boot        | 3.3.5   | Rapid microservices development       |
| **Language**       | Java               | 17 LTS  | Long-term support, modern features    |
| **Build Tool**     | Maven              | 3.9.6   | Dependency management, plugins        |
| **Container**      | Docker             | 24.x    | Consistent deployment environment     |
| **Orchestration**  | Docker Compose     | 2.x     | Multi-container management            |
| **Monitoring**     | Kafka UI           | Latest  | Visual monitoring and debugging       |

### Key Libraries

- **spring-kafka** 3.2.4 - Kafka integration
- **confluent-kafka-avro-serializer** 7.6.0 - Avro serialization
- **avro-maven-plugin** 1.11.3 - Code generation from schemas
- **spring-boot-starter-actuator** 3.3.5 - Health checks and metrics
- **lombok** 1.18.30 - Boilerplate reduction

---

## Project Structure

```
Big-data-Assignment/
â”‚
â”œâ”€â”€ producer-service/              # Order creation microservice
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ java/com/pramithamj/kafka/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ProducerServiceApplication.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ KafkaProducerConfig.java      # Kafka producer config
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ OrderController.java          # REST API endpoints
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ producer/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ OrderProducer.java            # Kafka message sender
â”‚   â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚   â”‚       â”œâ”€â”€ application.properties            # Local config
â”‚   â”‚   â”‚       â”œâ”€â”€ application-docker.properties     # Docker config
â”‚   â”‚   â”‚       â””â”€â”€ avro/
â”‚   â”‚   â”‚           â””â”€â”€ order.avsc                    # Avro schema
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”œâ”€â”€ Dockerfile                                     # Multi-stage build
â”‚   â”œâ”€â”€ .dockerignore                                  # Build optimization
â”‚   â””â”€â”€ pom.xml                                        # Maven dependencies
â”‚
â”œâ”€â”€ consumer-service/              # Order processing microservice
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main/
â”‚   â”‚   â”‚   â”œâ”€â”€ java/com/pramithamj/kafka/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ConsumerServiceApplication.java
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ aggregation/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ RunningAverageCalculator.java # Thread-safe aggregation
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ KafkaConsumerConfig.java      # Consumer config
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ KafkaProducerConfig.java      # For retry/DLQ
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ consumer/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ OrderConsumer.java            # Message listeners
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ controller/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ConsumerController.java       # Stats API
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ retry/
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ RetryHandler.java             # Exponential backoff
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ dlq/
â”‚   â”‚   â”‚   â”‚       â””â”€â”€ DLQHandler.java               # Dead letter queue
â”‚   â”‚   â”‚   â””â”€â”€ resources/
â”‚   â”‚   â”‚       â”œâ”€â”€ application.properties
â”‚   â”‚   â”‚       â”œâ”€â”€ application-docker.properties
â”‚   â”‚   â”‚       â””â”€â”€ avro/
â”‚   â”‚   â”‚           â””â”€â”€ order.avsc
â”‚   â”‚   â””â”€â”€ test/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ .dockerignore
â”‚   â””â”€â”€ pom.xml
â”‚
â”œâ”€â”€ infrastructure/                # Infrastructure as code
â”‚   â”œâ”€â”€ docker/
â”‚   â”‚   â”œâ”€â”€ docker-compose.yml                        # 9 containers orchestration
â”‚   â”‚   â”œâ”€â”€ .env                                      # Environment variables
â”‚   â”‚   â””â”€â”€ .env.example                              # Template
â”‚   â””â”€â”€ scripts/
â”‚       â”œâ”€â”€ quick-start.sh                            # One-command deployment
â”‚       â”œâ”€â”€ start-dashboard.sh                        # Dashboard launcher
â”‚       â”œâ”€â”€ create-topics.sh                          # Kafka topic creation
â”‚       â”œâ”€â”€ seed-data.sh                              # Test data generation
â”‚       â””â”€â”€ check-cluster.sh                          # Health check script
â”‚
â”œâ”€â”€ dashboard/                     # Web Dashboard (Port 3000)
â”‚   â”œâ”€â”€ index.html                                    # Main UI
â”‚   â”œâ”€â”€ styles.css                                    # Styling
â”‚   â”œâ”€â”€ app.js                                        # Frontend logic
â”‚   â”œâ”€â”€ nginx.conf                                    # Nginx config
â”‚   â”œâ”€â”€ Dockerfile                                    # Container build
â”‚   â””â”€â”€ README.md                                     # Dashboard docs
â”‚
â”œâ”€â”€ docs/                          # Comprehensive documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md                               # System architecture
â”‚   â”œâ”€â”€ MANUAL-STARTUP-DEMO-GUIDE.md                  # Step-by-step guide
â”‚   â””â”€â”€ DASHBOARD-DEMO-GUIDE.md                       # Dashboard demo scenarios
â”‚
â””â”€â”€ README.md                      # This file
```

---

## Deployment Options

### Option 1: Quick Start

**One command to deploy everything:**

```bash
./infrastructure/scripts/quick-start.sh
```

### Option 2: Step-by-Step Deployment

**Step 1: Start infrastructure**

```bash
cd infrastructure/docker
docker compose up -d zookeeper kafka1 kafka2 kafka3 schema-registry kafka-ui
```

**Step 2: Create topics**

```bash
cd ../scripts
./create-topics.sh
```

**Step 3: Build and deploy services**

```bash
cd ../../
docker compose -f infrastructure/docker/docker-compose.yml up -d producer-service consumer-service
```

## API Documentation

### Producer Service (Port 8090)

#### Send Single Order

```bash
POST http://localhost:8090/api/orders

Query Parameters:
- orderId: string (required) - Unique order identifier
- product: string (required) - Product name
- price: double (required) - Order amount

Example:
curl -X POST "http://localhost:8090/api/orders?orderId=ORD001&product=Laptop&price=999.99"

Response:
{
  "orderId": "2658",
  "success": true,
  "message": "Order sent to Kafka successfully"
}
```

#### Health Check

```bash
GET http://localhost:8090/actuator/health

Response:
{"status":"UP"}
```

### Consumer Service (Port 8082)

#### Get Statistics

```bash
GET http://localhost:8082/api/consumer/stats

Response:
{
    "ordersProcessed": 25,
    "totalAmount": 4567.89,
    "runningAverage": 182.72,
    "detailedStats": "Processed: 25 | Errors: 1 | Success Rate: 96.00% | Total Amount: $4567.89 | Running Average: $182.72"
}
```

#### Health Check

```bash
GET http://localhost:8082/actuator/health

Response:
{"status":"UP"}
```

### Schema Registry (Port 8081)

#### List Schemas

```bash
GET http://localhost:8081/subjects

Response:
["orders-value"]
```

#### Get Schema Details

```bash
GET http://localhost:8081/subjects/orders-value/versions/1

Response:
{
  "subject": "orders-value",
  "version": 1,
  "id": 1,
  "schema": "{...}"
}
```

---

## Monitoring & Operations

### Web Dashboard

**Access:** http://localhost:3000

**Features:**

- ** Real-time Statistics** - Total orders, running average, revenue, success rate
- **ðŸ› ï¸ Order Management** - Create single orders, random orders, or batch of 10
- **ðŸ“ˆ System Monitoring** - All 9 containers health status
- **ðŸ” Service Health** - Producer & consumer service checks
- **ðŸ“‹ Order History** - Recent orders table with status tracking
- **âš¡ Quick Actions** - Refresh, clear stats, export data

**Quick Start:**

```bash
./infrastructure/scripts/start-dashboard.sh
```

**Demo Guide:** [DASHBOARD-DEMO-GUIDE.md](docs/DASHBOARD-DEMO-GUIDE.md)

### Kafka UI Dashboard

**Access:** http://localhost:8080

**Features:**

- **Brokers** - Health status of all 3 Kafka nodes
- **Topics** - Message counts, partitions, replication
- **Messages** - Browse and inspect individual messages
- **Consumers** - Consumer groups, lag, assignments
- **Schemas** - Avro schema registry visualization

### Health Checks

```bash
# Check all containers
docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

# Check specific service
docker inspect producer-service --format='{{json .State.Health}}' | python3 -m json.tool

# Check Kafka cluster
./infrastructure/scripts/check-cluster.sh
```

### Logs

```bash
# View producer logs
docker logs producer-service --tail 50 --follow

# View consumer logs
docker logs consumer-service --tail 50 --follow

# View Kafka broker logs
docker logs kafka1 --tail 50 --follow

# View only order processing messages
docker logs consumer-service 2>&1 | grep "Received order"
```

### Metrics

```bash
# Consumer statistics
curl http://localhost:8082/api/consumer/stats | python3 -m json.tool

# Topic details
docker exec kafka1 kafka-topics --describe --bootstrap-server kafka1:19092 --topic orders

# Consumer group lag
docker exec kafka1 kafka-consumer-groups --describe \
  --bootstrap-server kafka1:19092 --group order-consumer-group
```

---

### Avro Schema

**File:** `producer-service/src/main/resources/avro/order.avsc`

```json
{
  "type": "record",
  "name": "Order",
  "namespace": "com.pramithamj.kafka.model",
  "fields": [
    {"name": "orderId", "type": "string"},
    {"name": "product", "type": "string"},
    {"name": "price", "type": "double"},
    {"name": "timestamp", "type": "long"}
  ]
}
```

## ðŸ‘¥ Authors

**Pramitha M.J.**

- GitHub: [@PramithaMJ](https://github.com/PramithaMJ)

## Quick Command Reference

```bash
# Start system
./infrastructure/scripts/quick-start.sh

# Stop system
docker compose -f infrastructure/docker/docker-compose.yml down

# Send order
curl -X POST "http://localhost:8090/api/orders?orderId=TEST&product=Item&price=99.99"

# Check stats
curl http://localhost:8082/api/consumer/stats | python3 -m json.tool

# View Kafka UI
open http://localhost:8080

# View logs
docker logs consumer-service --tail 50 --follow

# Health check
docker ps --format "table {{.Names}}\t{{.Status}}"

# Clean restart
docker compose -f infrastructure/docker/docker-compose.yml down -v && \
./infrastructure/scripts/quick-start.sh
```
